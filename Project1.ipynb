{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbb35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "seed(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc2e00",
   "metadata": {},
   "source": [
    "# Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import project1; import importlib; importlib.reload(project1); from project1.project1 import make_design_matrix\n",
    "N=5\n",
    "x, y = np.meshgrid(np.linspace(0,1,N),np.linspace(0,1,N))\n",
    "xvec  = np.array([x, y])\n",
    "X = make_design_matrix(xvec, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e59179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "N=5\n",
    "x, y = np.meshgrid(np.linspace(0,1,N),np.linspace(0,1,N))\n",
    "xvec  = np.array([x, y])\n",
    "xi = {\"x%i\"%i : xvec[i].ravel() for i in range(len(xvec))}\n",
    "keys = [key for key in xi.keys()]\n",
    "comb = []\n",
    "p = 2\n",
    "for p in range(1,p+1):\n",
    "    comb += [x for x in combinations_with_replacement(keys, p )]\n",
    "print(comb)\n",
    "X = make_design_matrix(xvec, p=2)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, y, n ):\n",
    "\tif len(x.shape) > 1:\n",
    "\t\tx = np.ravel(x)\n",
    "\t\ty = np.ravel(y)\n",
    "\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t# Number of elements in beta\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "\treturn X\n",
    "\n",
    "x, y = np.meshgrid(np.linspace(0,1,N),np.linspace(0,1,N))\n",
    "X_lecturer = create_X(x = x, y = y, n = 2)\n",
    "np.sum(X_lecturer == X) == len(X.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd837fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_lecturer)\n",
    "X_lecturer[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lecturer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93700a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X_lecturer, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1753aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lecturer[:,1] - np.mean(X_lecturer[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42fe19",
   "metadata": {},
   "source": [
    "# Time for generating design matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac039d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "model_complexity = 5\n",
    "xvec = np.array([x,y])\n",
    "for p in range(1,model_complexity+1):\n",
    "\n",
    "    tik = time.time()\n",
    "    X = make_design_matrix(xvec = xvec, p = p)\n",
    "    #X = create_X(x = x1, y=y1, n = p)\n",
    "    tok = time.time()\n",
    "    print(tok-tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d781dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "model_complexity = 5\n",
    "xvec = np.array([x1,y1])\n",
    "for p in range(1,model_complexity+1):\n",
    "    tik = time.time()\n",
    "    #X = make_design_matrix(xvec = xvec, p = p)\n",
    "    X = create_X(x = x, y=y, n = p)\n",
    "    tok = time.time()\n",
    "    print(tok-tik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc24fe",
   "metadata": {},
   "source": [
    "# Simple 1D test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9813ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import project1.project1;import importlib; importlib.reload(project1.project1);from project1.project1 import *\n",
    "x = np.arange(0,1,0.05)\n",
    "def test_func(**kwargs):\n",
    "    x = kwargs['x0']\n",
    "    return 5*x**2 + x\n",
    "\n",
    "xvec  = np.array([x])\n",
    "X = make_design_matrix(xvec = xvec, p = 5)\n",
    "z = test_func(**{'x0':x})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "znoisy_centered = np.array([[x] for x in znoisy - np.mean(znoisy)])\n",
    "A = np.linalg.pinv(X.T@X)@X.T\n",
    "betahat = A@znoisy_centered\n",
    "znoisy_tilde = X@betahat\n",
    "plt.plot(x, znoisy_centered, linestyle = 'dashed')\n",
    "plt.plot(x, znoisy_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import project1.project1;import importlib; importlib.reload(project1.project1);from project1.project1 import *\n",
    "x = np.arange(0,1,0.05)\n",
    "xvec = np.array([x])\n",
    "z = test_func(**{'x0':x})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "znoisy_centered = znoisy - np.mean(znoisy)\n",
    "X = make_design_matrix(xvec = xvec, p = 5)\n",
    "znoisy_tilde, betahat = ols_fp_wo_split(X = X, y = znoisy_centered)\n",
    "plt.plot(x, znoisy_centered, linestyle = 'dashed')\n",
    "plt.plot(x, znoisy_tilde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22291755",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import project1.project1;import importlib; importlib.reload(project1.project1);from project1.project1 import *\n",
    "x, y = np.arange(0,1,0.1), np.arange(0,1,0.1)\n",
    "x, y = np.meshgrid(x,y)\n",
    "def test_func_2(**kwargs):\n",
    "    x = kwargs['x0']\n",
    "    y = kwargs['x1']\n",
    "    return 5*x**2 + x + 5*y**2 + y + np.exp(-x**2) +np.exp(-x*y) + np.exp(-y) \n",
    "xvec = np.array([x, y])\n",
    "X = make_design_matrix(xvec = xvec, p = 5)\n",
    "z = test_func_2(**{'x%i'%i: xvec[i] for i in range(len(xvec))})\n",
    "\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "znoisy_centered = znoisy - np.mean(znoisy)\n",
    "znoisy_tilde, betahat = ols_fp_wo_split(X = X, y = znoisy_centered.ravel())\n",
    "znoisy_tilde = znoisy_tilde.reshape(x.shape)\n",
    "znoisy = znoisy.reshape(x.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection':'3d'}, figsize=(10,10))\n",
    "ax.plot_surface(x,y,znoisy_tilde + np.mean(znoisy), cmap=cm.viridis)\n",
    "ax.plot_surface(x,y,z, cmap=cm.coolwarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a1fa1",
   "metadata": {},
   "source": [
    "# b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd45e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib; import project1; importlib.reload(project1)\n",
    "from project1.project1 import *\n",
    "x, y = np.meshgrid(np.arange(0,1,0.05),np.arange(0,1,0.05))\n",
    "xvec = np.array([x,y])\n",
    "z = FrankeFunction(**{'x%i'%i: xvec[i] for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "znoisy_centered = znoisy - np.mean(znoisy)\n",
    "for p in range(1,6):\n",
    "    X = make_design_matrix(xvec = xvec, p = p)\n",
    "    znoisy_tilde, betahat = ols_fp_wo_split(X = X, y = znoisy_centered.ravel())\n",
    "znoisy_tilde = (znoisy_tilde + np.mean(znoisy)).reshape(x.shape)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection':'3d'}, figsize=(10,10))\n",
    "ax.plot_surface(x,y,znoisy_tilde, cmap=cm.viridis)\n",
    "ax.plot_surface(x,y,z, cmap=cm.coolwarm)\n",
    "ax.view_init(20,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib; import project1; importlib.reload(project1)\n",
    "from project1.project1 import *\n",
    "test_size = 0.3\n",
    "for N in [50,100, 500]:\n",
    "    x, y = np.meshgrid(np.linspace(0,1,N),np.linspace(0,1,N))\n",
    "    xvec = np.array([x,y])\n",
    "    maxdeg = 10\n",
    "    mses_train = np.zeros((maxdeg))\n",
    "    mses_test = np.zeros((maxdeg))\n",
    "    Rs_train = np.zeros((maxdeg))\n",
    "    Rs_test = np.zeros((maxdeg))\n",
    "\n",
    "    betas = []\n",
    "    z = FrankeFunction(**{'x%i'%i: xvec[i] for i in range(len(xvec))})\n",
    "    noise = np.random.normal(0,1,size=z.shape)\n",
    "    znoisy = z + noise\n",
    "    for p in range(1,maxdeg+1):\n",
    "        print(p)\n",
    "        #X = make_design_matrix(xvec = xvec, p = p)\n",
    "        X = create_X(x = xvec[0].ravel(), y = xvec[1].ravel(), n = p)\n",
    "\n",
    "        Xtrain, Xtest, znoisy_train, znoisy_test = train_test_split(X, znoisy.ravel(), \n",
    "                                                                    **{'random_state' : 42, 'test_size':test_size})\n",
    "        scale = 1/np.sqrt(np.sum(znoisy_train**2))\n",
    "        ztilde_train, betahat = ols_fp_wo_split(X = Xtrain, y = scale*(znoisy_train-np.mean(znoisy_train)))\n",
    "\n",
    "        ztilde_train = (1/scale)*ztilde_train + np.mean(znoisy_train)\n",
    "        ztilde_test = (1/scale)*Xtest@betahat + np.mean(znoisy_train)\n",
    "        betas.append(betahat)\n",
    "\n",
    "        mses_train[p-1] = MSE(y = znoisy_train,ytilde = ztilde_train)\n",
    "        mses_test[p-1] = MSE(y = znoisy_test,ytilde = ztilde_test )\n",
    "        Rs_train[p-1] = Rscore(y = znoisy_train, ytilde = ztilde_train)\n",
    "        Rs_test[p-1] = Rscore(y = znoisy_test, ytilde = ztilde_test)\n",
    "\n",
    "    fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "    polydeg = np.arange(maxdeg)+1\n",
    "    fig.suptitle(\"$N=%i$, testsize $%.1f$ percentage\"%(N, test_size*100))\n",
    "    axs[0].plot(polydeg, mses_train, ls=\"--\", marker='o', label=\"Train\")\n",
    "    axs[0].plot(polydeg, mses_test, marker='o', label=\"Test\")\n",
    "    axs[0].set_ylabel(\"MSE\")\n",
    "    axs[1].plot(polydeg, Rs_train, marker='o', ls = \"--\", label = \"Train\")\n",
    "    axs[1].plot(polydeg, Rs_test, marker='o', label = \"Test\")\n",
    "\n",
    "    axs[1].set_ylabel(\"$R^2$ score\")\n",
    "    [ax.set_xlabel(\"Polynomial degree $p$\") for ax in axs]\n",
    "    [ax.set_xticks(polydeg, polydeg) for ax in axs]\n",
    "    [ax.legend() for ax in axs]\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cfe9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "beta_matrix = np.ones((maxdeg, len(betas[-1])))*np.nan\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(maxdeg):\n",
    "    for j in range(len(betas[i])):\n",
    "        beta_matrix[i,j] = betas[i][j]\n",
    "[plt.plot(np.arange(maxdeg) + 1, beta_matrix[:,i], label=\"$\\\\beta%i$\"%i) for i in range(beta_matrix.shape[-1])]\n",
    "plt.ylabel(\"$\\\\beta$\")\n",
    "plt.xlabel(\"Polynomial degree $p$\")\n",
    "plt.legend(ncol = 2, bbox_to_anchor=(1,.5,.15,.5))\n",
    "plt.xticks(np.arange(maxdeg) + 1,np.arange(maxdeg) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da0378",
   "metadata": {},
   "source": [
    "# c)\n",
    "\n",
    "To plot surface data retrieve the indices from the uniqueness of the xy-coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11140dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, y = np.meshgrid(np.arange(0,1,0.01),np.arange(0,1,0.01))\n",
    "xvec = np.array([x,y])\n",
    "X = make_design_matrix(xvec = xvec, p = 4)\n",
    "z = FrankeFunction(**{'x%i'%i: xvec[i].ravel() for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,.1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "ztilde_train, ztilde_test, betahat, Xtrain, Xtest, ztrain,ztest = ols_fp_train_test_split(X = X, y = znoisy, \n",
    "                                                                                          **{\"test_size\" : 0.25, \n",
    "                                                                                             \"random_state\" : 42})\n",
    "xtrain = Xtrain[:,1]\n",
    "ytrain = Xtrain[:,2]\n",
    "shape_train = (x.shape[0], len(ytrain)//x.shape[0])\n",
    "xtest = Xtest[:,1]\n",
    "ytest = Xtest[:,2]\n",
    "shape_test = (x.shape[0], len(ytest)//x.shape[0])\n",
    "\n",
    "fig, axs = plt.subplots(2,2,subplot_kw={'projection':'3d'}, figsize=(10,10))\n",
    "axs[0,0].scatter(xtrain, ytrain, ztilde_train, c=ztilde_train, cmap=cm.viridis)\n",
    "#axs[0].scatter(xtrain, ytrain, ztrain, c=ztrain, cmap=cm.coolwarm)\n",
    "axs[0,1].scatter(xtrain, ytrain, np.mean(z)+ztrain-ztilde_train, c=np.mean(z)+ztrain-ztilde_train, cmap=cm.coolwarm)\n",
    "\n",
    "axs[1,0].scatter(xtest, ytest, ztilde_test, c=ztilde_test, cmap=cm.viridis)\n",
    "#axs[1].scatter(xtest, ytest, ztest, c=ztest, cmap=cm.coolwarm)\n",
    "axs[1,1].scatter(xtest, ytest, ztest + np.mean(z)-ztilde_test, c=np.mean(z)+ztest-ztilde_test, cmap=cm.coolwarm)\n",
    "[ax.view_init(15,45) for ax in axs.ravel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e2b2cb",
   "metadata": {},
   "source": [
    "# Bias-variance trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903555ae",
   "metadata": {},
   "source": [
    "### 1D test case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57eacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func_exp(**kwargs):\n",
    "    x = kwargs['x0']\n",
    "    return np.exp(x -x**2) + 5*x**2 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070eac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2022)\n",
    "import importlib; import project1; importlib.reload(project1)\n",
    "from project1.project1 import *\n",
    "model_complexity = 20\n",
    "mses_train, Rs_train = np.zeros((model_complexity)), np.zeros((model_complexity))\n",
    "mses_test, Rs_test = np.zeros((model_complexity)), np.zeros((model_complexity))\n",
    "x = np.arange(0,1,0.01)\n",
    "xvec = np.array([x])\n",
    "z = test_func_exp(**{'x%i'%i: xvec[i].ravel() for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "for p in range(1,model_complexity+1):\n",
    "    X = make_design_matrix(xvec = xvec, p = p)\n",
    "    \n",
    "    ztilde_train, ztilde_test, betahat, Xtrain, Xtest, ztrain,ztest = ols_fp_train_test_split(X = X, y = znoisy, \n",
    "                                                                                              **{\"test_size\" : 0.3, \n",
    "                                                                                                \"random_state\" : 42})\n",
    "    mses_train[p-1] = MSE(y = ztrain,ytilde = ztilde_train)\n",
    "    Rs_train[p-1] = Rscore(y = ztrain, ytilde = ztilde_train)\n",
    "    \n",
    "    mses_test[p-1] = MSE(y = ztest,ytilde = ztilde_test)\n",
    "    Rs_test[p-1] = Rscore(y = ztest, ytilde = ztilde_test)\n",
    "    \n",
    "ps = [i for i in range(1,model_complexity+1)]\n",
    "plt.plot(ps, np.log10(mses_train), label=\"MSE train\")\n",
    "plt.plot(ps, np.log10(mses_test), label=\"MSE test\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"log10 MSE\")\n",
    "plt.xlabel(\"Polynomial degree\")\n",
    "plt.xticks(np.arange(model_complexity)[::2]+1,np.arange(20)[::2]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ac75a",
   "metadata": {},
   "source": [
    "## 2D Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func_2(**kwargs):\n",
    "    x = kwargs['x0']\n",
    "    y = kwargs['x1']\n",
    "    return np.exp(x -(x+y)**2) + 5*x**2 + x*y\n",
    "\n",
    "model_complexity = 10\n",
    "mses_train, Rs_train = np.zeros((model_complexity)), np.zeros((model_complexity))\n",
    "mses_test, Rs_test = np.zeros((model_complexity)), np.zeros((model_complexity))\n",
    "x, y = np.meshgrid(np.arange(0,1,0.05),np.arange(0,1,0.05))\n",
    "xvec = np.array([x,y])\n",
    "z = test_func_2(**{'x%i'%i: xvec[i].ravel() for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "for p in range(1,model_complexity+1):\n",
    "    X = make_design_matrix(xvec = xvec, p = p)\n",
    "    \n",
    "    ztilde_train, ztilde_test, betahat, Xtrain, Xtest, ztrain,ztest = ols_fp_train_test_split(X = X, y = znoisy, \n",
    "                                                                                              **{\"test_size\" : 0.3, \n",
    "                                                                                                \"random_state\" : 42})\n",
    "    mses_train[p-1] = MSE(y = ztrain,ytilde = ztilde_train)\n",
    "    Rs_train[p-1] = Rscore(y = ztrain, ytilde = ztilde_train)\n",
    "    \n",
    "    mses_test[p-1] = MSE(y = ztest,ytilde = ztilde_test)\n",
    "    Rs_test[p-1] = Rscore(y = ztest, ytilde = ztilde_test)\n",
    "# plot log10(MSE) wrt to the polynomial degree\n",
    "ps = [i for i in range(1,model_complexity+1)]\n",
    "plt.plot(ps, np.log10(mses_train), label=\"MSE train\")\n",
    "plt.plot(ps, np.log10(mses_test), label=\"MSE test\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"log10 MSE\")\n",
    "plt.xlabel(\"Polynomial degree\")\n",
    "plt.xticks(np.arange(model_complexity)[::2]+1,np.arange(model_complexity)[::2]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71527e5",
   "metadata": {},
   "source": [
    "# Bias-variance trade-off Franke function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complexity = 20\n",
    "x, y = np.meshgrid(np.arange(0,1,0.05),np.arange(0,1,0.05))\n",
    "xvec = np.array([x,y])\n",
    "mses_train, Rs_train, bias_train, variance_train = np.zeros((model_complexity)), np.zeros((model_complexity)),np.zeros((model_complexity)), np.zeros((model_complexity))\n",
    "mses_test, Rs_test, bias_test, variance_test = np.zeros((model_complexity)), np.zeros((model_complexity)),np.zeros((model_complexity)), np.zeros((model_complexity))\n",
    "\n",
    "z = FrankeFunction(**{'x%i'%i: xvec[i].ravel() for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "for p in range(1,model_complexity+1):\n",
    "    X = make_design_matrix(xvec = xvec, p = p)\n",
    "    ztilde_train, ztilde_test, betahat, Xtrain, Xtest, ztrain,ztest = ols_fp_train_test_split(X = X, y = znoisy, \n",
    "                                                                                              **{\"test_size\" : 0.3, \n",
    "                                                                                                \"random_state\" : 42})\n",
    "    \n",
    "    mses_train[p-1] = MSE(y = ztrain,ytilde = ztilde_train)\n",
    "    Rs_train[p-1] = Rscore(y = ztrain, ytilde = ztilde_train)\n",
    "    bias_train[p-1] = np.mean((ztrain-np.mean(ztilde_train))**2)\n",
    "    variance_train[p-1] = np.var(ztilde_train)\n",
    "    \n",
    "    mses_test[p-1] = MSE(y = ztest,ytilde = ztilde_test)\n",
    "    Rs_test[p-1] = Rscore(y = ztest, ytilde = ztilde_test)\n",
    "    bias_test[p-1] = np.mean((ztest-np.mean(ztilde_test))**2)\n",
    "    variance_test[p-1] = np.var(ztilde_test)\n",
    "\n",
    "# plot log10(MSE) wrt polynomial degrees\n",
    "ps = [i for i in range(1,model_complexity+1)]\n",
    "#plt.plot(ps, np.log10(mses_train), label=\"MSE train\")\n",
    "plt.plot(ps, np.log10(mses_test), label=\"MSE test\")\n",
    "#plt.plot(ps, np.log10(bias_train), label=\"Bias train\")\n",
    "plt.plot(ps, np.log10(bias_test), label=\"Bias test\")\n",
    "#plt.plot(ps, np.log10(variance_train), label=\"Var train\")\n",
    "plt.plot(ps, np.log10(variance_test), label=\"Var test\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"log10(MSE)\")\n",
    "plt.xlabel(\"Polynomial degree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdd8af5",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "model_complexity = 20\n",
    "k = 100\n",
    "x, y = np.meshgrid(np.arange(0,1,0.05),np.arange(0,1,0.05))\n",
    "xvec = np.array([x,y])\n",
    "mses_train, Rs_train, bias_train, variance_train = np.zeros((model_complexity, k)), np.zeros((model_complexity,k)),np.zeros((model_complexity, k)), np.zeros((model_complexity,k))\n",
    "mses_test, Rs_test, bias_test, variance_test = np.zeros((model_complexity, k)), np.zeros((model_complexity, k)),np.zeros((model_complexity, k)), np.zeros((model_complexity, k))\n",
    "\n",
    "z = FrankeFunction(**{'x%i'%i: xvec[i].ravel() for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "\n",
    "for p in range(1,model_complexity+1):\n",
    "    print(p)\n",
    "    X = make_design_matrix(xvec = xvec, p = p)\n",
    "    Xtrain, Xtest, ztrain,ztest = train_test_split(X, znoisy,**{\"test_size\" : 0.25, \"random_state\" : 42})\n",
    "    for ik in range(k):\n",
    "        z_resampled = resample(data = ztrain)\n",
    "        X_resampled = resample(data = Xtrain)\n",
    "        ztilde_train, betahat = ols_fp_wo_split(X=Xtrain, y=ztrain)\n",
    "        ztilde_test = Xtest@betahat\n",
    "        mses_train[p-1, ik] = MSE(y = ztrain,ytilde = ztilde_train)\n",
    "        Rs_train[p-1, ik] = Rscore(y = ztrain, ytilde = ztilde_train)\n",
    "        bias_train[p-1, ik] = np.mean((ztrain-np.mean(ztilde_train))**2)\n",
    "        variance_train[p-1, ik] = np.var(ztilde_train)\n",
    "\n",
    "        mses_test[p-1, ik] = MSE(y = ztest,ytilde = ztilde_test)\n",
    "        Rs_test[p-1, ik] = Rscore(y = ztest, ytilde = ztilde_test)\n",
    "        bias_test[p-1, ik] = np.mean((ztest-np.mean(ztilde_test))**2)\n",
    "        variance_test[p-1, ik] = np.var(ztilde_test)\n",
    "\n",
    "# plot log10(MSE) wrt polynomial degrees\n",
    "ps = [i for i in range(1,model_complexity+1)]\n",
    "#plt.plot(ps, np.log10(np.mean(mses_train, axis = 1)), label=\"MSE train\")\n",
    "plt.plot(ps, np.log10(np.mean(mses_test, axis = 1)), label=\"MSE test\")\n",
    "#plt.plot(ps, np.log10(np.mean(bias_train, axis = 1)), label=\"Bias train\")\n",
    "plt.plot(ps, np.log10(np.mean(bias_test, axis = 1)), label=\"Bias test\")\n",
    "#plt.plot(ps, np.log10(np.mean(variance_train, axis = 1)), label=\"Var train\")\n",
    "plt.plot(ps, np.log10(np.mean(variance_test, axis = 1)), label=\"Var test\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"log10(MSE)\")\n",
    "plt.xlabel(\"Polynomial degree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6246ca",
   "metadata": {},
   "source": [
    "# d) cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6dea0",
   "metadata": {},
   "source": [
    "### Testing the standardscaler from SL and compare it to own code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a796b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "N = 10; p=2\n",
    "x, y = np.meshgrid(np.linspace(0,1,N),np.linspace(0,1,N))\n",
    "X = create_X(x = x, y=y, n=p)\n",
    "print(X)\n",
    "scaler = StandardScaler(with_std=True)\n",
    "scaler.fit(X)\n",
    "Xscaled_SL = scaler.transform(X)\n",
    "Xscaled = scale_center_X(X=X)\n",
    "print(Xscaled_SL, Xscaled)\n",
    "Xscaled_SL == Xscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296fd40",
   "metadata": {},
   "source": [
    "## Franke function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9969221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "model_complexity = 20\n",
    "x, y = np.meshgrid(np.arange(0,1,0.05),np.arange(0,1,0.05))\n",
    "xvec = np.array([x,y])\n",
    "z = FrankeFunction(**{'x%i'%i: xvec[i].ravel() for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "k = 5\n",
    "mses_train, var_train, bias_train, variance_train = np.zeros((model_complexity, k)), np.zeros((model_complexity,k)),np.zeros((model_complexity, k)), np.zeros((model_complexity,k))\n",
    "mses_test, var_test, bias_test, variance_test = np.zeros((model_complexity, k)), np.zeros((model_complexity, k)),np.zeros((model_complexity, k)), np.zeros((model_complexity, k))\n",
    "for p in range(1,model_complexity+1):\n",
    "    mses_train[p-1], mses_test[p-1], bias_train[p-1], bias_test[p-1], var_train[p-1], var_test[p-1] = cross_validation(data = znoisy, xvec = xvec, k = k, p = p, method = \"ols\")\n",
    "# plot log10(MSE) wrt polynomial degree\n",
    "ps = [i for i in range(1,model_complexity+1)]\n",
    "#plt.plot(ps, np.log10(np.mean(mses_train, axis = 1)), label=\"MSE train\")\n",
    "plt.plot(ps, np.log10(np.mean(mses_test, axis = 1)), label=\"MSE test\")\n",
    "#plt.plot(ps, np.log10(np.mean(bias_train, axis = 1)), label=\"Bias train\")\n",
    "plt.plot(ps, np.log10(np.mean(bias_test, axis = 1)), label=\"Bias test\")\n",
    "#plt.plot(ps, np.log10(np.mean(var_train, axis = 1)), label=\"Var train\")\n",
    "plt.plot(ps, np.log10(np.mean(var_test, axis = 1)), label=\"Var test\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"log10(MSE)\")\n",
    "plt.xlabel(\"Polynomial degree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8f35b",
   "metadata": {},
   "source": [
    "### Ridge comparison $\\lambda = 0$\n",
    "- should give similar features as the OLS\n",
    "    - but bias is tending to increase with the polynomial degree..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "model_complexity = 20\n",
    "x, y = np.meshgrid(np.arange(0,1,0.05),np.arange(0,1,0.05))\n",
    "xvec = np.array([x,y])\n",
    "z = FrankeFunction(**{'x%i'%i: xvec[i] for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "k = 5\n",
    "mses_train, var_train, bias_train, variance_train = np.zeros((model_complexity, k)), np.zeros((model_complexity,k)),np.zeros((model_complexity, k)), np.zeros((model_complexity,k))\n",
    "mses_test, var_test, bias_test, variance_test = np.zeros((model_complexity, k)), np.zeros((model_complexity, k)),np.zeros((model_complexity, k)), np.zeros((model_complexity, k))\n",
    "for p in range(1,model_complexity+1):\n",
    "    mses_train[p-1], mses_test[p-1], bias_train[p-1], bias_test[p-1], var_train[p-1], var_test[p-1] = cross_validation(data = znoisy, xvec = xvec, k = k, p = p, method = \"ridge\", lmbda=0, scale_centering=True)\n",
    "# plot log10(MSE) wrt polynomial degree\n",
    "ps = [i for i in range(1,model_complexity+1)]\n",
    "#plt.plot(ps, np.log10(np.mean(mses_train, axis = 1)), label=\"MSE train\")\n",
    "plt.plot(ps, np.log10(np.mean(mses_test, axis = 1)), label=\"MSE test\")\n",
    "#plt.plot(ps, np.log10(np.mean(bias_train, axis = 1)), label=\"Bias train\")\n",
    "plt.plot(ps, np.log10(np.mean(bias_test, axis = 1)), label=\"Bias test\")\n",
    "#plt.plot(ps, np.log10(np.mean(var_train, axis = 1)), label=\"Var train\")\n",
    "plt.plot(ps, np.log10(np.mean(var_test, axis = 1)), label=\"Var test\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"log10(MSE)\")\n",
    "plt.xlabel(\"Polynomial degree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747c492",
   "metadata": {},
   "source": [
    "# e) Ridge with CV and bootstrap\n",
    "-Â Bias-variance trade-off\n",
    "- MSE and R2-score\n",
    "- study dependence on $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e72a4a0",
   "metadata": {},
   "source": [
    "## CV\n",
    "- check: for $\\lambda = 0$ do I get the same as the OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010bf990",
   "metadata": {},
   "source": [
    "## Simple test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f07fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "\n",
    "# A seed just to ensure that the random numbers are the same for every run.\n",
    "# Useful for eventual debugging.\n",
    "np.random.seed(3155)\n",
    "\n",
    "# Generate the data.\n",
    "nsamples = 50\n",
    "x = np.random.randn(nsamples)\n",
    "y = 3*x**2 + np.random.randn(nsamples)\n",
    "p = 6\n",
    "k = 5\n",
    "# Decide which values of lambda to use\n",
    "nlambdas = 500\n",
    "lambdas = np.logspace(-3, 5, nlambdas)\n",
    "mses_train, var_train, bias_train = np.zeros((len(lambdas), k)), np.zeros((len(lambdas), k)),np.zeros((len(lambdas), k))\n",
    "mses_test, var_test, bias_test = np.zeros((len(lambdas), k)), np.zeros((len(lambdas), k)),np.zeros((len(lambdas), k))\n",
    "splits = kfold(data=y, k=k, random_state = 3155)\n",
    "for i in range(len(lambdas)):\n",
    "    mses_train[i], mses_test[i], bias_train[i], bias_test[i], var_train[i], var_test[i] = cross_validation(data = y, splits = splits, xvec = np.array([x]), k = k, p = p, method = \"ridge\", lmbda = lambdas[i], scale_centering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde326c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "# Initialize a KFold instance\n",
    "k = 5\n",
    "kfold = KFold(n_splits = k, random_state=3155, shuffle=True)\n",
    "poly = PolynomialFeatures(degree = p)\n",
    "estimated_mse_sklearn = np.zeros(nlambdas)\n",
    "i = 0\n",
    "for lmb in lambdas:\n",
    "    # generate model\n",
    "    ridge = Ridge(alpha = lmb)\n",
    "    # make design matrix\n",
    "    X_SL = poly.fit_transform(x[:, np.newaxis])\n",
    "    # scale design matrix\n",
    "    X_SL_scaled = scale_center_X(X = X_SL[:,1:])\n",
    "    # perform cross-validation\n",
    "    estimated_mse_folds = cross_val_score(ridge, X_SL_scaled, y[:, np.newaxis]-np.mean(y[:, np.newaxis]), \n",
    "                                          scoring='neg_mean_squared_error', cv=kfold)\n",
    "    # store mse values\n",
    "    estimated_mse_sklearn[i] = np.mean(-estimated_mse_folds)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log10(lambdas), np.log10(np.mean(mses_test, axis=1)), label=\"MSE test\")\n",
    "#plt.plot(np.log10(lambdas), np.log10(np.mean(mses_train, axis=1)), label=\"MSE train\")\n",
    "\n",
    "plt.plot(np.log10(lambdas), np.log10(estimated_mse_sklearn), label = 'cross_val_score')\n",
    "#plt.plot(np.log10(lambdas), np.log10(np.mean(mses_test, axis=1))-np.log10(estimated_mse_sklearn), label = 'diff')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be400f70",
   "metadata": {},
   "source": [
    "## Franke function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f20332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "x, y = np.meshgrid(np.arange(0,1,0.05),np.arange(0,1,0.05))\n",
    "xvec = np.array([x,y])\n",
    "z = FrankeFunction(**{'x%i'%i: xvec[i] for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "model_complexity = 20\n",
    "k = 5\n",
    "lambdas = np.array([0]+list(np.logspace(-5,5,10)))\n",
    "mses_train, bias_train, var_train = np.zeros((model_complexity, len(lambdas), k)),np.zeros((model_complexity, len(lambdas), k)),np.zeros((model_complexity, len(lambdas), k))\n",
    "mses_test, bias_test, var_test = np.zeros((model_complexity, len(lambdas), k)),np.zeros((model_complexity, len(lambdas), k)),np.zeros((model_complexity, len(lambdas), k))\n",
    "for p in range(1, model_complexity+1):\n",
    "    print(p)\n",
    "    X = make_design_matrix(xvec = xvec, p = p)\n",
    "    splits = kfold(data=y, k=k, random_state = 3155)\n",
    "    for i in range(len(lambdas)):\n",
    "        #print(lambdas[i])\n",
    "        mses_train[p-1, i], mses_test[p-1, i], bias_train[p-1, i], bias_test[p-1, i], var_train[p-1, i], var_test[p-1, i] = cross_validation(data = znoisy, splits = splits, xvec = xvec, k = k, p = p, method = \"ridge\", lmbda = lambdas[i], scale_centering=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,len(lambdas), figsize=(len(lambdas)*5,5), sharey=True)\n",
    "\n",
    "ps = np.arange(model_complexity)+1\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "    if lambdas[i] == 0:\n",
    "        axs[i].set_title(\"$\\\\lambda = 0$\")\n",
    "    else:    \n",
    "        axs[i].set_title(\"$\\\\lambda = 10^{%.3f}$\"%np.log10(lambdas[i]))\n",
    "    axs[i].plot(ps, np.log10(np.mean(mses_train[:,i],axis=1)),  label=\"MSE train\", color = 'b')\n",
    "    axs[i].plot(ps, np.log10(np.mean(mses_test[:,i], axis=1)),  label=\"MSE test\",  color = 'b', ls='--')\n",
    "    axs[i].plot(ps, np.log10(np.mean(bias_train[:,i],axis=1)),  label=\"(Bias[$\\\\tilde{\\mathbf{y}}_\\mathrm{train}$]$)^{2}$\",color = 'C1')\n",
    "    axs[i].plot(ps, np.log10(np.mean(bias_test[:,i], axis=1)),  label=\"(Bias[$\\\\tilde{\\mathbf{y}}_\\mathrm{train}$]$)^{2}$\", color = 'C1', ls='--')\n",
    "    axs[i].plot(ps, np.log10(np.mean(var_train[:,i], axis=1)),  label=\"Var train\", color = 'C2')\n",
    "    axs[i].plot(ps, np.log10(np.mean(var_test[:,i],  axis=1)),  label=\"Var test\",  color = 'C2', ls='--')\n",
    "[ax.set_ylabel(\"log10(MSE)\") for ax in axs]\n",
    "[ax.set_xlabel(\"Polynomial degree\") for ax in axs]\n",
    "[ax.legend() for ax in axs]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2339857",
   "metadata": {},
   "outputs": [],
   "source": [
    "carr = np.arange(mses_train.shape[0])/mses_train.shape[0]\n",
    "cs_train = plt.cm.copper(carr)\n",
    "cs_test = plt.cm.cool(carr)\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "for ip in range(mses_train.shape[0]):\n",
    "    ax.plot(lambdas, np.mean(mses_train[ip], axis=1), color = cs_train[ip], label=\"Train p = %i\"%(ip+1))\n",
    "    ax.plot(lambdas, np.mean(mses_test[ip], axis=1), color = cs_test[ip], label=\"Test p = %i\"%(ip+1))\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(.8,2)\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_xlabel(\"$\\\\lambda$\")\n",
    "ax.legend(bbox_to_anchor=(1.1,.9,0,.1), ncol=2)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d36928",
   "metadata": {},
   "source": [
    "## with bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "model_complexity = 20\n",
    "k = 20\n",
    "x, y = np.meshgrid(np.arange(0,1,0.05),np.arange(0,1,0.05))\n",
    "xvec = np.array([x,y])\n",
    "lambdas = np.logspace(-5,5, 10)\n",
    "\n",
    "mses_train, var_train, bias_train = np.zeros((model_complexity,len(lambdas), k)), np.zeros((model_complexity,len(lambdas),k)),np.zeros((model_complexity, len(lambdas),k)) \n",
    "mses_test, var_test, bias_test = np.zeros((model_complexity,len(lambdas), k)), np.zeros((model_complexity, len(lambdas), k)),np.zeros((model_complexity,len(lambdas), k))\n",
    "for p in range(1,model_complexity+1):\n",
    "    print(p)\n",
    "    X = make_design_matrix(xvec = xvec, p = p)[:,1:]\n",
    "    z = FrankeFunction(**{'x%i'%i: xvec[i].ravel() for i in range(len(xvec))})\n",
    "    noise = np.random.normal(0,1,size=z.shape)\n",
    "    znoisy = z + noise\n",
    "    Xtrain, Xtest, ztrain, ztest = train_test_split(X, znoisy)\n",
    "    X_test_scaled = scale_center_X(X = Xtest)\n",
    "    Xtrain_scaled = scale_center_X(X = Xtrain)\n",
    "    for ik in range(k):\n",
    "        z_resampled = resample(data = ztrain)\n",
    "        Xtrain_scaled_resampled = resample(data = Xtrain_scaled)      \n",
    "        for i in range(len(lambdas)):\n",
    "            ztilde_train, betahat = ridge_fp_wo_split(X=Xtrain_scaled_resampled, y=z_resampled-np.mean(z_resampled), lmbda = lambdas[i])\n",
    "            ztilde_train += np.mean(z_resampled)\n",
    "            ztilde_test = X_test_scaled@betahat + np.mean(z_resampled)\n",
    "            mses_train[p-1, i, ik] = MSE(y = z_resampled ,ytilde = ztilde_train)\n",
    "            bias_train[p-1, i, ik] = np.mean((z_resampled-np.mean(ztilde_train))**2)\n",
    "            var_train[p-1, i, ik] = np.var(ztilde_train)\n",
    "\n",
    "            mses_test[p-1, i, ik] = MSE(y = ztest,ytilde = ztilde_test)\n",
    "            bias_test[p-1, i, ik] = np.mean((ztest-np.mean(ztilde_test))**2)\n",
    "            var_test[p-1, i, ik] = np.var(ztilde_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,len(lambdas), figsize=(len(lambdas)*5,5), sharey=True)\n",
    "\n",
    "ps = np.arange(model_complexity)+1\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "    if lambdas[i] == 0:\n",
    "        axs[i].set_title(\"$\\\\lambda = 0$\")\n",
    "    else:    \n",
    "        axs[i].set_title(\"$\\\\lambda = 10^{%.3f}$\"%np.log10(lambdas[i]))\n",
    "    #axs[i].plot(ps, np.log10(np.mean(mses_train[:,i],axis=1)),  label=\"MSE train\", color = 'b')\n",
    "    axs[i].plot(ps, np.log10(np.mean(mses_test[:,i], axis=1)),  label=\"MSE test\",  color = 'b', ls='--')\n",
    "    #axs[i].plot(ps, np.log10(np.mean(bias_train[:,i],axis=1)),  label=\"Bias train\",color = 'C1')\n",
    "    axs[i].plot(ps, np.log10(np.mean(bias_test[:,i], axis=1)),  label=\"Bias test\", color = 'C1', ls='--')\n",
    "    #axs[i].plot(ps, np.log10(np.mean(var_train[:,i], axis=1)),  label=\"Var train\", color = 'C2')\n",
    "    axs[i].plot(ps, np.log10(np.mean(var_test[:,i],  axis=1)),  label=\"Var test\",  color = 'C2', ls='--')\n",
    "[ax.set_ylabel(\"log10(MSE)\") for ax in axs]\n",
    "[ax.set_xlabel(\"Polynomial degree\") for ax in axs]\n",
    "[ax.legend() for ax in axs]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfb396",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,len(lambdas), figsize=(len(lambdas)*5,5), sharey=True)\n",
    "\n",
    "ps = np.arange(model_complexity)+1\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "    if lambdas[i] == 0:\n",
    "        axs[i].set_title(\"$\\\\lambda = 0$\")\n",
    "    else:    \n",
    "        axs[i].set_title(\"$\\\\lambda = 10^{%.3f}$\"%np.log10(lambdas[i]))\n",
    "    axs[i].plot(ps, np.log10(np.mean(mses_train[:,i],axis=1)),  label=\"MSE train\", color = 'b')\n",
    "    axs[i].plot(ps, np.log10(np.mean(mses_test[:,i], axis=1)),  label=\"MSE test\",  color = 'b', ls='--')\n",
    "    #axs[i].plot(ps, np.log10(np.mean(bias_train[:,i],axis=1)),  label=\"Bias train\",color = 'C1')\n",
    "    axs[i].plot(ps, np.log10(np.mean(bias_test[:,i], axis=1)),  label=\"Bias test\", color = 'C1', ls='--')\n",
    "    #axs[i].plot(ps, np.log10(np.mean(var_train[:,i], axis=1)),  label=\"Var train\", color = 'C2')\n",
    "    axs[i].plot(ps, np.log10(np.mean(var_test[:,i],  axis=1)),  label=\"Var test\",  color = 'C2', ls='--')\n",
    "[ax.set_ylabel(\"log10(MSE)\") for ax in axs]\n",
    "[ax.set_xlabel(\"Polynomial degree\") for ax in axs]\n",
    "[ax.legend() for ax in axs]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,model_complexity,figsize=(model_complexity*5,5), sharey=True)\n",
    "for p in range(model_complexity):\n",
    "    axs[p].set_title(\"$p = %i$\"%(p+1))\n",
    "    axs[p].plot(lambdas, np.log10(np.mean(mses_train[p], axis=1)), label=\"MSE Train\")\n",
    "    axs[p].plot(lambdas, np.log10(np.mean(mses_test[p], axis=1)), label=\"MSE Test\") \n",
    "    #axs[p].plot(lambdas, np.log10(np.mean(bias_train[p], axis=1)), label=\"Bias Train\")\n",
    "    #axs[p].plot(lambdas, np.log10(np.mean(bias_test[p], axis=1)), label=\"Bias Test\") \n",
    "    #axs[p].plot(lambdas, np.log10(np.mean(var_train[p], axis=1)), label=\"$\\\\sigma^2$ Train\")\n",
    "    #axs[p].plot(lambdas, np.log10(np.mean(var_test[p], axis=1)), label=\"$\\\\sigma^2$ Test\") \n",
    "[ax.set_xlabel('log10($\\\\lambda$)') for ax in axs]\n",
    "[ax.set_xscale('log') for ax in axs]\n",
    "[ax.legend() for ax in axs]\n",
    "[ax.set_ylabel(\"log10(MSE)\") for ax in axs]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "carr = np.arange(mses_train.shape[0])/mses_train.shape[0]\n",
    "cs_train = plt.cm.copper(carr)\n",
    "cs_test = plt.cm.cool(carr)\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "for ip in range(mses_train.shape[0]):\n",
    "    ax.plot(lambdas, np.mean(mses_train[ip], axis=1), color = cs_train[ip], label=\"Train p = %i\"%(ip+1))\n",
    "    ax.plot(lambdas, np.mean(mses_test[ip], axis=1), color = cs_test[ip], label=\"Test p = %i\"%(ip+1))\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(.1,10)\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_xlabel(\"$\\\\lambda$\")\n",
    "ax.legend(bbox_to_anchor=(1.1,.9,0,.1), ncol=2)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b74bb7",
   "metadata": {},
   "source": [
    "# f) Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77478c10",
   "metadata": {},
   "source": [
    "## Test case\n",
    "\n",
    "### UiO example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9791f144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2.]\n",
      "Training MSE for OLS\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "X = np.array( [ [ 2, 0], [0, 1], [0,0]])\n",
    "y = np.array( [4, 2, 3])\n",
    "\n",
    "\n",
    "# matrix inversion to find beta\n",
    "OLSbeta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "print(OLSbeta)\n",
    "# and then make the prediction\n",
    "ytildeOLS = X @ OLSbeta\n",
    "print(\"Training MSE for OLS\")\n",
    "print(MSE(y,ytildeOLS))\n",
    "ypredictOLS = X @ OLSbeta\n",
    "\n",
    "# Repeat now for Ridge regression and various values of the regularization parameter\n",
    "I = np.eye(2,2)\n",
    "# Decide which values of lambda to use\n",
    "nlambdas = 100\n",
    "MSERidgePredict = np.zeros(nlambdas)\n",
    "MSELassoPredict = np.zeros(nlambdas)\n",
    "lambdas = np.logspace(-4, 4, nlambdas)\n",
    "for i in range(nlambdas):\n",
    "    lmb = lambdas[i]\n",
    "    X_scaled = scale_center_X(X = X)\n",
    "    Ridgebeta = np.linalg.inv(X_scaled.T @ X_scaled+lmb*I) @ X_scaled.T @ (y-np.mean(y))\n",
    "    #print(Ridgebeta)\n",
    "    # and then make the prediction\n",
    "    ypredictRidge = X_scaled @ Ridgebeta + np.mean(y)\n",
    "    MSERidgePredict[i] = MSE(y,ypredictRidge)\n",
    "    RegLasso = linear_model.Lasso(lmb, fit_intercept=True)\n",
    "    RegLasso.fit(X_scaled,y-np.mean(y))\n",
    "    ypredictLasso = RegLasso.predict(X_scaled) + np.mean(y)\n",
    "    #print(RegLasso.coef_)\n",
    "    MSELassoPredict[i] = MSE(y,ypredictLasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61d2ea39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.legend.Legend at 0x7f6455f460d0>,\n",
       " <matplotlib.legend.Legend at 0x7f6455f465e0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "\n",
    "MSERidgePredict_own = np.zeros(nlambdas)\n",
    "MSELassoPredict_own = np.zeros(nlambdas)\n",
    "for i in range(nlambdas):\n",
    "    ypredictRidge_own, Ridgebeta_own = ridge_fp_wo_split(X = X, y = y, lmbda=lambdas[i])\n",
    "    # and then make the prediction\n",
    "    MSERidgePredict_own[i] = MSE(y,ypredictRidge_own)\n",
    "    ypredictLasso_own,Lassobeta_own  = lasso_fp_wo_split(X = X, y = y, lmbda=lambdas[i])\n",
    "    MSELassoPredict_own[i] = MSE(y,ypredictLasso_own)\n",
    "# Now plot the results\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "axs[0].plot(np.log10(lambdas), MSERidgePredict, 'C1--', label = 'MSE Ridge Train')\n",
    "axs[1].plot(np.log10(lambdas), MSELassoPredict, 'C2--', label = 'MSE Lasso Train')\n",
    "axs[0].plot(np.log10(lambdas), MSERidgePredict_own, 'b-', label = 'Own MSE Ridge Train', alpha=0.5)\n",
    "axs[1].plot(np.log10(lambdas), MSELassoPredict_own, 'r--', label = 'Own MSE Lasso Train')\n",
    "[ax.set_xlabel('log10(lambda)') for ax in axs]\n",
    "[ax.set_ylabel('MSE') for ax in axs]\n",
    "[ax.legend() for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a7b0bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now plot the difference of the results\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "axs[0].plot(np.log10(lambdas), MSERidgePredict-MSERidgePredict_own, 'b-', label = 'Own MSE Ridge Train', alpha=0.5)\n",
    "axs[1].plot(np.log10(lambdas), MSELassoPredict-MSELassoPredict_own, 'r--', label = 'Own MSE Lasso Train')\n",
    "plt.xlabel('log10(lambda)')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952aaf92",
   "metadata": {},
   "source": [
    "## Franke function\n",
    "### Bootstrapping bias-variacne trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "model_complexity = 5\n",
    "k = 100\n",
    "x, y = np.meshgrid(np.arange(0,1,0.01),np.arange(0,1,0.01))\n",
    "xvec = np.array([x,y])\n",
    "z = FrankeFunction(**{'x%i'%i: xvec[i].ravel() for i in range(len(xvec))})\n",
    "noise = np.random.normal(0,1,size=z.shape)\n",
    "znoisy = z + noise\n",
    "    \n",
    "lambdas = np.logspace(-10,5, 20)\n",
    "\n",
    "mses_train, var_train, bias_train = np.zeros((model_complexity,len(lambdas), k)), np.zeros((model_complexity,len(lambdas),k)),np.zeros((model_complexity, len(lambdas),k)) \n",
    "mses_test, var_test, bias_test = np.zeros((model_complexity,len(lambdas), k)), np.zeros((model_complexity, len(lambdas), k)),np.zeros((model_complexity,len(lambdas), k))\n",
    "for p in range(1,model_complexity+1):\n",
    "    print(p)\n",
    "    X = make_design_matrix(xvec = xvec, p = p)[:,1:]    \n",
    "    Xtrain, Xtest, ztrain, ztest = train_test_split(X, znoisy)\n",
    "    Xtest_scaled = scale_center_X(X = Xtest)\n",
    "    for ik in range(k):\n",
    "        z_resampled = resample(data = ztrain)\n",
    "        mean_zresampled = np.mean(z_resampled)\n",
    "        Xtrain_resampled = resample(data = Xtrain)\n",
    "        for i in range(len(lambdas)):\n",
    "            ztilde_train, betahat = lasso_fp_wo_split(X=Xtrain_resampled, y=z_resampled-mean_zresampled, lmbda = lambdas[i],**{'fit_intercept':True})\n",
    "            ztilde_train += mean_zresampled\n",
    "            ztilde_test = Xtest_scaled@betahat + mean_zresampled\n",
    "            mses_train[p-1, i, ik] = MSE(y = z_resampled ,ytilde = ztilde_train)\n",
    "            bias_train[p-1, i, ik] = np.mean((z_resampled-mean_zresampled)**2)\n",
    "            var_train[p-1, i, ik] = np.var(ztilde_train)\n",
    "\n",
    "            mses_test[p-1, i, ik] = MSE(y = ztest,ytilde = ztilde_test)\n",
    "            bias_test[p-1, i, ik] = np.mean((ztest-mean_zresampled)**2)\n",
    "            var_test[p-1, i, ik] = np.var(ztilde_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,model_complexity,figsize=(model_complexity*5,5), sharey=True)\n",
    "for p in range(model_complexity):\n",
    "    axs[p].set_title(\"$p = %i$\"%(p+1))\n",
    "    axs[p].plot(lambdas, np.log10(np.mean(mses_train[p], axis=1)), label=\"MSE Train\")\n",
    "    axs[p].plot(lambdas, np.log10(np.mean(mses_test[p], axis=1)), label=\"MSE Test\") \n",
    "    #axs[p].plot(lambdas, np.log10(np.mean(bias_train[p], axis=1)), label=\"Bias Train\")\n",
    "    #axs[p].plot(lambdas, np.log10(np.mean(bias_test[p], axis=1)), label=\"Bias Test\") \n",
    "    #axs[p].plot(lambdas, np.log10(np.mean(var_train[p], axis=1)), label=\"$\\\\sigma^2$ Train\")\n",
    "    #axs[p].plot(lambdas, np.log10(np.mean(var_test[p], axis=1)), label=\"$\\\\sigma^2$ Test\") \n",
    "[ax.set_xscale('log') for ax in axs]\n",
    "\n",
    "[ax.legend() for ax in axs]\n",
    "[ax.set_ylabel(\"log10(MSE)\") for ax in axs]\n",
    "[ax.set_xlabel(\"$\\\\lambda$\") for ax in axs]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782e76d",
   "metadata": {},
   "source": [
    "## CV MSE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828cfa27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import project1.project1; import importlib; importlib.reload(project1.project1); from project1.project1 import *\n",
    "\n",
    "mses_train, var_train, bias_train, variance_train = np.zeros((model_complexity,len(lambdas), k)), np.zeros((model_complexity,len(lambdas),k)),np.zeros((model_complexity, len(lambdas),k)), np.zeros((model_complexity,len(lambdas),k))\n",
    "mses_test, var_test, bias_test, variance_test = np.zeros((model_complexity,len(lambdas), k)), np.zeros((model_complexity, len(lambdas), k)),np.zeros((model_complexity,len(lambdas), k)), np.zeros((model_complexity, len(lambdas),k))\n",
    "\n",
    "for p in range(1, model_complexity+1):\n",
    "    print(p)\n",
    "    #X = make_design_matrix(xvec = xvec, p = p)\n",
    "    X = create_X(x = x, y=y, n = p)\n",
    "    splits = kfold(data=znoisy, k=k, random_state = 3155)\n",
    "    for i in range(len(lambdas)):\n",
    "        mses_train[p-1,i], mses_test[p-1,i], bias_train[p-1,i], bias_test[p-1,i], var_train[p-1,i], var_test[p-1,i] = cross_validation(data = znoisy, splits = splits, xvec = xvec, k = k, p = p, method = \"lasso\", lmbda = lambdas[i], scale_centering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,model_complexity,figsize=(model_complexity*5,5), sharey=True)\n",
    "for p in range(model_complexity):\n",
    "    axs[p].set_title(\"$p=%i$\"%(p+1))\n",
    "    axs[p].plot(lambdas, np.log10(np.mean(mses_train[p], axis=1)), label=\"Train\")\n",
    "    axs[p].plot(lambdas, np.log10(np.mean(mses_test[p], axis=1)), label=\"Test\") \n",
    "[ax.set_xscale('log') for ax in axs]\n",
    "[ax.legend() for ax in axs]\n",
    "[ax.set_ylabel(\"log10(MSE)\") for ax in axs]\n",
    "[ax.set_xlabel(\"$\\\\lambda$\") for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,len(lambdas), figsize=(len(lambdas)*5,5), sharey=True)\n",
    "ps = np.arange(model_complexity)+1\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "    axs[i].set_title(\"$\\\\lambda = 10^{%.3f}$\"%np.log10(lambdas[i]))\n",
    "    axs[i].plot(ps, np.log10(np.mean(mses_train[:,i], axis=1)), label=\"Train\", color='b')\n",
    "    axs[i].plot(ps, np.log10(np.mean(mses_test[:,i], axis=1)), label=\"Test\", color = 'C1')\n",
    "[ax.set_ylabel(\"log10(MSE)\") for ax in axs]\n",
    "[ax.set_xlabel(\"Polynomial degree\") for ax in axs]\n",
    "[ax.legend() for ax in axs]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ab50e",
   "metadata": {},
   "source": [
    "# Real data \n",
    "# g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa50964",
   "metadata": {},
   "source": [
    "### plot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7af56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "datadir = \"~/cs/ada_ml/ada_ml_project1/datafiles\"\n",
    "terrain1 = np.array(imread(datadir + \"/SRTM_data_Norway_1.tif\"))\n",
    "terrain2 = np.array(imread(datadir + \"/SRTM_data_Norway_2.tif\"))\n",
    "fig, axs = plt.subplots(1,2, figsize = (10,5))\n",
    "fig_3d, axs_3d = plt.subplots(1,2, subplot_kw={'projection':'3d'}, figsize = (10,5))\n",
    "im1 = axs[0].imshow(terrain1, cmap = plt.cm.terrain)\n",
    "im2 = axs[1].imshow(terrain2, cmap = plt.cm.terrain)\n",
    "cbar1 = fig.colorbar(im1, ax = axs[0])\n",
    "cbar2 = fig.colorbar(im2, ax = axs[1])\n",
    "x1, y1 = np.meshgrid(np.linspace(0,1, terrain1.shape[1]), np.linspace(0,1, terrain1.shape[0]) )\n",
    "x2, y2 = np.meshgrid(np.linspace(0,1, terrain2.shape[1]), np.linspace(0,1, terrain2.shape[0]) )\n",
    "axs_3d[0].plot_surface(x1, y1, terrain1/np.sqrt(np.sum(terrain1**2)), cmap =plt.cm.terrain)\n",
    "axs_3d[1].plot_surface(x2, y2, terrain2/np.sqrt(np.sum(terrain2**2)), cmap =plt.cm.terrain)\n",
    "[ax.view_init(20,45) for ax in axs_3d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab19b9d",
   "metadata": {},
   "source": [
    "## Test OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a14836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "p = 10\n",
    "xvec = np.array([x1,y1])\n",
    "\n",
    "#X = make_design_matrix(xvec = xvec, p = p)\n",
    "X = create_X(x = x1, y=y1, n = p)\n",
    "Xtrain, Xtest, ztrain, ztest = train_test_split(X, terrain1.ravel(), **{'random_state' : 42, 'test_size' : 0.3})\n",
    "ztilde_train, betahat = ols_fp_wo_split(X=Xtrain, y=ztrain-np.mean(ztrain))\n",
    "ztilde_train += np.mean(ztrain)\n",
    "ztilde_test = Xtest@betahat + np.mean(ztrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9245782",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3d, axs_3d = plt.subplots(1,2, subplot_kw={'projection':'3d'}, figsize = (10,5))\n",
    "axs_3d[0].scatter(Xtrain[:,1][::100], \n",
    "                  Xtrain[:,2][::100], \n",
    "                  ztilde_train[::100], \n",
    "                  c=ztilde_train[::100], cmap = plt.cm.terrain)\n",
    "axs_3d[1].scatter(Xtest[:,1][::100], \n",
    "                  Xtest[:,2][::100], \n",
    "                  ztilde_test[::100], \n",
    "                  c = ztilde_test[::100], cmap = plt.cm.terrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0496c50",
   "metadata": {},
   "source": [
    "## Bias-variance trade-off analysis\n",
    "1. OLS\n",
    "2. Ridge\n",
    "3. Lasso\n",
    "\n",
    "with bootstrap and cross-validation in order to make a full comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d7d3fd",
   "metadata": {},
   "source": [
    "### OLS bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3421e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "model_complexity = 10\n",
    "k = int(10)\n",
    "xvec = np.array([x1,y1])\n",
    "\n",
    "mses_train, var_train, bias_train = np.zeros((model_complexity, k)), np.zeros((model_complexity,k)),np.zeros((model_complexity,k)) \n",
    "mses_test, var_test, bias_test = np.zeros((model_complexity, k)), np.zeros((model_complexity, k)),np.zeros((model_complexity, k))\n",
    "for p in range(1,model_complexity+1):\n",
    "    print(p)\n",
    "    #X = make_design_matrix(xvec = xvec, p = p)\n",
    "    X = create_X(x = x1, y=y1, n = p)\n",
    "    Xtrain, Xtest, ztrain, ztest = train_test_split(X, terrain1.ravel())\n",
    "    for ik in range(k):\n",
    "        z_resampled = resample(data =ztrain)\n",
    "        ztilde_train, betahat = ols_fp_wo_split(X=Xtrain, y=z_resampled-np.mean(z_resampled))\n",
    "        ztilde_train += np.mean(z_resampled)\n",
    "        ztilde_test = Xtest@betahat + np.mean(z_resampled)\n",
    "        mses_train[p-1, ik] = MSE(y = ztrain ,ytilde = ztilde_train)\n",
    "        bias_train[p-1, ik] = np.mean((ztrain-np.mean(ztilde_train))**2)\n",
    "        var_train[p-1, ik] = np.var(ztilde_train)\n",
    "\n",
    "        mses_test[p-1,ik] = MSE(y = ztest ,ytilde = ztilde_test)\n",
    "        bias_test[p-1,ik] = np.mean((ztest-np.mean(ztilde_test))**2)\n",
    "        var_test[p-1, ik] = np.var(ztilde_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ps = np.arange(model_complexity)+1\n",
    "ax.set_title(\"$p = %i$\"%(model_complexity))\n",
    "ax.errorbar(ps, np.log10(np.mean(mses_train, axis=1)),yerr=np.log10(np.std(mses_train, axis=1)), label=\"MSE Train\")\n",
    "ax.errorbar(ps, np.log10(np.mean(mses_test, axis=1)), yerr=np.log10(np.std(mses_test, axis=1)),  label=\"MSE Test\" ) \n",
    "ax.errorbar(ps, np.log10(np.mean(bias_train, axis=1)),yerr=np.log10(np.std(bias_train, axis=1)), label=\"Bias Train\",        marker = 'x')\n",
    "ax.errorbar(ps, np.log10(np.mean(bias_test, axis=1)), yerr=np.log10(np.std(bias_test, axis=1)),  label=\"Bias Test\",         marker = 'x') \n",
    "ax.errorbar(ps, np.log10(np.mean(var_train, axis=1)), yerr=np.log10(np.std(var_train, axis=1)),  label=\"$\\\\sigma^2$ Train\", marker = '^')\n",
    "ax.errorbar(ps, np.log10(np.mean(var_test, axis=1)),  yerr=np.log10(np.std(var_test, axis=1)),   label=\"$\\\\sigma^2$ Test\",  marker = '^') \n",
    "ax.legend()\n",
    "ax.set_ylabel(\"log10(MSE)\")\n",
    "ax.set_xticks(ps, ps)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eafda5",
   "metadata": {},
   "source": [
    "## For profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1351c0",
   "metadata": {},
   "source": [
    "# CV OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663eea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, xvec, k, p, method, lmbda = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "\n",
    "    data - data to be fitted, ndarray\n",
    "    k - number of folds, int\n",
    "    p - polynomial degree, int\n",
    "\n",
    "    Out:\n",
    "\n",
    "\n",
    "    mses - MSEs for each train test pair, np array with dim = (k,)\n",
    "\n",
    "    \"\"\"    \n",
    "    # b is flat array of data to fit\n",
    "    b = data.ravel()\n",
    "    indices = np.arange(len(b.ravel()))\n",
    "    isplit = np.full(k, len(b.ravel()) // k, dtype = int)\n",
    "    isplit[:len(b.ravel()) % k] += 1\n",
    "    isplit = np.cumsum(isplit)\n",
    "    np.random.shuffle(indices)\n",
    "    splits = np.split(np.arange(len(b.ravel()))[indices], isplit[:-1])\n",
    "    # initiating the inferences\n",
    "    mses_train = np.zeros((k))\n",
    "    mses_test = np.zeros((k))\n",
    "    bias_train = np.zeros((k))\n",
    "    bias_test = np.zeros((k))\n",
    "    var_train = np.zeros((k))\n",
    "    var_test = np.zeros((k))\n",
    "    for itest in range(k):\n",
    "        test = splits[np.array(itest, dtype = int)]\n",
    "        train = np.concatenate(np.delete(splits, np.array(itest, dtype=int), axis=0))\n",
    "        #Xtrain = make_design_matrix(xvec = np.array([x.ravel()[train] for x in xvec]), p = p)\n",
    "        Xtrain = create_X(x = xvec[0].ravel()[train], y = xvec[1].ravel()[train], n = p)\n",
    "        #Xtest = make_design_matrix(xvec = np.array([x.ravel()[test] for x in xvec]), p = p)\n",
    "        Xtest = create_X(x = xvec[0].ravel()[test], y = xvec[1].ravel()[test], n = p)\n",
    "        if method == \"ols\":\n",
    "            data_tilde_train, betahat = ols_fp_wo_split(X = Xtrain, y = b[train] - np.mean(b[train]))\n",
    "            data_tilde_train += np.mean(b[train])\n",
    "            data_tilde_test = Xtest@betahat + np.mean(b[train])\n",
    "        if method == \"lasso\":\n",
    "            if lmbda is None:\n",
    "                raise ValueError(\"Lambda value has not been set\")\n",
    "            clf_train = linear_model.Lasso(alpha = lmbda)\n",
    "            clf_train.fit(X=Xtrain, y = b[train]-np.mean(b[train]))\n",
    "            betahat = clf_train.coef_\n",
    "            data_tilde_train = Xtrain@betahat + np.mean(b[train])\n",
    "            data_tilde_test = Xtest@betahat + np.mean(b[train])\n",
    "        if method == \"ridge\":\n",
    "            if lmbda is None:\n",
    "                raise ValueError(\"Lambda value has not been set\")\n",
    "            data_tilde_train, betahat = ridge_fp_wo_split(X=Xtrain, y=b[train]-np.mean(b[train]), lmbda=lmbda)\n",
    "            data_tilde_train += np.mean(b[train])\n",
    "            data_tilde_test = Xtest@betahat + np.mean(b[train])\n",
    "        mses_train[itest] = MSE(y = b[train], ytilde = data_tilde_train)\n",
    "        mses_test[itest]  = MSE(y = b[test], ytilde = data_tilde_test)\n",
    "        bias_train[itest] = bias(y = b[train], ytilde = data_tilde_train)\n",
    "        bias_test[itest]  = bias(y = b[test], ytilde = data_tilde_test)\n",
    "        var_train[itest]  = np.var(data_tilde_train)\n",
    "        var_test[itest]   = np.var(data_tilde_test)\n",
    "\n",
    "    return mses_train, mses_test, bias_train, bias_test, var_train, var_test\n",
    "   \n",
    "model_complexity = 5\n",
    "xvec = np.array([x1[::10,::10],y1[::10,::10]])\n",
    "k = 6\n",
    "mses_train, var_train, bias_train, variance_train = np.zeros((model_complexity, k)), np.zeros((model_complexity,k)),np.zeros((model_complexity, k)), np.zeros((model_complexity,k))\n",
    "mses_test, var_test, bias_test, variance_test = np.zeros((model_complexity, k)), np.zeros((model_complexity, k)),np.zeros((model_complexity, k)), np.zeros((model_complexity, k))\n",
    "p = model_complexity + 1 \n",
    "%lprun -f cross_validation cross_validation(data = terrain1[::10,::10], xvec = xvec, k = k, p = p, method = \"ridge\", lmbda = 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac2fb9",
   "metadata": {},
   "source": [
    "### OLS cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "model_complexity = 10\n",
    "xvec = np.array([x1,y1])\n",
    "scale = 1/np.sqrt(np.sum(terrain1**2))\n",
    "k = 6\n",
    "mses_train_ols, var_train_ols, bias_train_ols = np.zeros((model_complexity, k)), np.zeros((model_complexity,k)),np.zeros((model_complexity, k))\n",
    "mses_test_ols,  var_test_ols,  bias_test_ols = np.zeros((model_complexity, k)), np.zeros((model_complexity, k)),np.zeros((model_complexity, k))\n",
    "for p in range(1,model_complexity+1):\n",
    "    print(p)\n",
    "    mses_train_ols[p-1], mses_test_ols[p-1], bias_train_ols[p-1], bias_test_ols[p-1], var_train_ols[p-1], var_test_ols[p-1] = cross_validation(data = scale*terrain1, xvec = xvec, k = k, p = p, method = \"ols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2462f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,5), sharey=True)\n",
    "ps = np.arange(model_complexity) + 1\n",
    "ax.plot(ps, np.log10((1/scale)*np.mean(mses_train_ols, axis=1)), ls = '--', label=\"MSE Train\")\n",
    "ax.plot(ps, np.log10((1/scale)*np.mean(mses_test_ols, axis=1)), label=\"MSE Test\") \n",
    "ax.plot(ps, np.log10((1/scale)*np.mean(bias_train_ols, axis=1)), ls = '--', label=\"Bias Train\")\n",
    "ax.plot(ps, np.log10((1/scale)*np.mean(bias_test_ols, axis=1)), label=\"Bias Test\") \n",
    "ax.plot(ps, np.log10((1/scale)*np.mean(var_train_ols, axis=1)), ls = '--', label=\"Var Train\")\n",
    "ax.plot(ps, np.log10((1/scale)*np.mean(var_test_ols, axis=1)), label=\"Var Test\") \n",
    "#ax.set_xscale('log')\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"log10(MSE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cadf8c",
   "metadata": {},
   "source": [
    "## Ridge CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8cfe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "model_complexity = 10\n",
    "xvec = np.array([x1,y1])\n",
    "k = 6\n",
    "lambdas = np.logspace(-5,5, 10)\n",
    "ll = len(lambdas)\n",
    "mses_train_ridge, var_train_ridge, bias_train_ridge = np.zeros((model_complexity, ll,k)), np.zeros((model_complexity, ll,k)),np.zeros((model_complexity,  ll,k))\n",
    "mses_test_ridge, var_test_ridge, bias_test_ridge = np.zeros((model_complexity,  ll,k)), np.zeros((model_complexity,  ll,k)),np.zeros((model_complexity,  ll,k))\n",
    "for p in range(1,model_complexity+1):\n",
    "    print(p)\n",
    "    for i in range(len(lambdas)):\n",
    "        print(p, i)\n",
    "        mses_train_ridge[p-1, i], mses_test_ridge[p-1, i], bias_train_ridge[p-1, i], bias_test_ridge[p-1, i], var_train_ridge[p-1, i], var_test_ridge[p-1, i] = cross_validation(data = terrain1, xvec = xvec, k = k, p = p, method = \"ridge\", lmbda = lambdas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(model_complexity//2):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5), sharey=True)\n",
    "    ax.plot(lambdas, np.log10(np.mean(mses_train_ridge[i], axis=1)), ls = '--', label=\"MSE Train\")\n",
    "    ax.plot(lambdas, np.log10(np.mean(mses_test_ridge[i], axis=1)), label=\"MSE Test\") \n",
    "    ax.plot(lambdas, np.log10(np.mean(bias_train_ridge[i], axis=1)), ls = '--', label=\"Bias Train\")\n",
    "    ax.plot(lambdas, np.log10(np.mean(bias_test_ridge[i], axis=1)), label=\"Bias Test\") \n",
    "    ax.plot(lambdas, np.log10(np.mean(var_train_ridge[i], axis=1)), ls = '--', label=\"Var Train\")\n",
    "    ax.plot(lambdas, np.log10(np.mean(var_test_ridge[i], axis=1)), label=\"Var Test\") \n",
    "    ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_ylabel(\"log10(MSE)\")\n",
    "    ax.set_ylim(4,5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64822712",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(model_complexity//2):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5), sharey=True)\n",
    "    ax.plot(lambdas, np.log10(np.mean(mses_train_ridge[i], axis=1)), ls = '--', label=\"MSE Train\")\n",
    "    ax.plot(lambdas, np.log10(np.mean(mses_test_ridge[i], axis=1)), label=\"MSE Test\") \n",
    "    ax.plot(lambdas, np.log10(np.mean(bias_train_ridge[i], axis=1)), ls = '--', label=\"Bias Train\")\n",
    "    ax.plot(lambdas, np.log10(np.mean(bias_test_ridge[i], axis=1)), label=\"Bias Test\") \n",
    "    ax.plot(lambdas, np.log10(np.mean(var_train_ridge[i], axis=1)), ls = '--', label=\"Var Train\")\n",
    "    ax.plot(lambdas, np.log10(np.mean(var_test_ridge[i], axis=1)), label=\"Var Test\") \n",
    "    ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_ylabel(\"log10(MSE)\")\n",
    "    ax.set_ylim(4,5.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce56c8",
   "metadata": {},
   "source": [
    "# Lasso CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import project1; importlib.reload(project1); from project1.project1 import *\n",
    "model_complexity = 5\n",
    "xvec = np.array([x1,y1])\n",
    "k = 5\n",
    "lambdas = np.logspace(-5,5, 10)\n",
    "ll = len(lambdas)\n",
    "mses_train_lasso, var_train_lasso, bias_train_lasso = np.zeros((model_complexity, ll,k)), np.zeros((model_complexity, ll,k)),np.zeros((model_complexity,  ll,k))\n",
    "mses_test_lasso, var_test_lasso, bias_test_lasso = np.zeros((model_complexity,  ll,k)), np.zeros((model_complexity,  ll,k)),np.zeros((model_complexity,  ll,k))\n",
    "for p in range(1,model_complexity+1):\n",
    "    print(p)\n",
    "    for i in range(len(lambdas)):\n",
    "        print(p, i)\n",
    "        mses_train[p-1, i], mses_test[p-1, i], bias_train[p-1, i], bias_test[p-1, i], var_train[p-1, i], var_test[p-1, i] = cross_validation(data = terrain1, xvec = xvec, k = k, p = p, \n",
    "                                                                                                                                             method = \"lasso\", lmbda = lambdas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6169927",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,ll, figsize=(ll*5,5))\n",
    "\n",
    "ps = np.arange(model_complexity)+1\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "    if lambdas[i] == 0:\n",
    "        axs[i].set_title(\"$\\\\lambda = 0$\")\n",
    "    else:    \n",
    "        axs[i].set_title(\"$\\\\lambda = 10^{%.3f}$\"%np.log10(lambdas[i]))\n",
    "    axs[i].plot(ps, np.log10(np.mean(mses_train[:,i],axis=1)),  label=\"MSE train\", color = 'b')\n",
    "    axs[i].plot(ps, np.log10(np.mean(mses_test[:,i], axis=1)),  label=\"MSE test\",  color = 'b', ls='--')\n",
    "    axs[i].plot(ps, np.log10(np.mean(bias_train[:,i],axis=1)),  label=\"Bias train\",color = 'C1')\n",
    "    axs[i].plot(ps, np.log10(np.mean(bias_test[:,i], axis=1)),  label=\"Bias test\", color = 'C1', ls='--')\n",
    "    axs[i].plot(ps, np.log10(np.mean(var_train[:,i], axis=1)),  label=\"Var train\", color = 'C2')\n",
    "    axs[i].plot(ps, np.log10(np.mean(var_test[:,i],  axis=1)),  label=\"Var test\",  color = 'C2', ls='--')\n",
    "[ax.set_ylabel(\"log10(MSE)\") for ax in axs]\n",
    "[ax.set_xlabel(\"Polynomial degree\") for ax in axs]\n",
    "[ax.legend() for ax in axs]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5), sharey=True)\n",
    "    ax.plot(lambdas, np.log10(np.mean(mses_train[i], axis=1)), ls = '--', label=\"MSE Train\")\n",
    "    ax.plot(lambdas, np.log10(np.mean(mses_test[i], axis=1)), label=\"MSE Test\") \n",
    "    ax.plot(lambdas, np.log10(np.mean(bias_train[i], axis=1)), ls = '--', label=\"Bias Train\")\n",
    "    ax.plot(lambdas, np.log10(np.mean(bias_test[i], axis=1)), label=\"Bias Test\") \n",
    "    ax.plot(lambdas, np.log10(np.mean(var_train[i], axis=1)), ls = '--', label=\"Var Train\")\n",
    "    ax.plot(lambdas, np.log10(np.mean(var_test[i], axis=1)), label=\"Var Test\") \n",
    "    ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_ylabel(\"log10(MSE)\")\n",
    "    ax.set_ylim(4,5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cbcfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
